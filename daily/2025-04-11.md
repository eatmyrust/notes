# Slack templates for Alertmanager
Alertmanager can be configured to send custom text utilizing variables with information about the alert that was received
```yaml
global:
  slack_api_url: '<slack_webhook_url>'

route:
  receiver: 'slack-notifications'
  group_by: [alertname, datacenter, app]

receivers:
- name: 'slack-notifications'
  slack_configs:
  - channel: '#alerts'
    text: 'https://internal.myorg.net/wiki/alerts/{{ .GroupLabels.app }}/{{ .GroupLabels.alertname }}'
```
Prometheus alert rules can be configured to send variables with useful information about the alert to alertmanager
###### Prometheus Rule
```yaml
groups:
- name: Instances
  rules:
  - alert: InstanceDown
    expr: up == 0
    for: 5m
    labels:
      severity: page
    # Prometheus templates apply here in the annotation and label fields of the alert.
    annotations:
      description: '{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.'
      summary: 'Instance {{ $labels.instance }} down'
```
These variables can then be used in the Alertmanager config
###### Receiver
```yaml
- name: 'team-x'
  slack_configs:
  - channel: '#alerts'
    # Alertmanager templates apply here.
    text: "<!channel> \nsummary: {{ .CommonAnnotations.summary }}\ndescription: {{ .CommonAnnotations.description }}"
```
###### Range Function in Receiver
```yaml
- name: 'default-receiver'
  slack_configs:
  - channel: '#alerts'
    title: "{{ range .Alerts }}{{ .Annotations.summary }}\n{{ end }}"
    text: "{{ range .Alerts }}{{ .Annotations.description }}\n{{ end }}"
```
Reusable templates can be defined to reduce the amount of text required in the Alertmanager configuration.
###### Reusable Template in a File /alertmanager/template/myorg.tmpl
```text
{{ define "slack.myorg.text" }}https://internal.myorg.net/wiki/alerts/{{ .GroupLabels.app }}/{{ .GroupLabels.alertname }}{{ end}}
```
###### Alertmanager Config Using Template
```yaml
global:
  slack_api_url: '<slack_webhook_url>'

route:
  receiver: 'slack-notifications'
  group_by: [alertname, datacenter, app]

receivers:
- name: 'slack-notifications'
  slack_configs:
  - channel: '#alerts'
    text: '{{ template "slack.myorg.text" . }}'

templates:
- '/etc/alertmanager/templates/myorg.tmpl'
```

-------------------------------------------------
# Alertmanager
Prometheus separates alerting into two parts. A prometheus server contains alerting rules, which send alerts to an Alertmanager. The Alertmanager then handles those rules and implements silencing, inhibition, aggregation, and sending the alerts out through alerting channels like slack or email.
## Features
### Grouping
Categorize similar alerts into a single notification. Rather than getting thousands of notifications when a networking error occurs and services cannot reach a database, get a single notification that contains information about each service that is failing. This is configured by a routing tree in the Altertmanager configuration file.
### Inhibition
This is the concept of suppressing certain alerts when other alerts are already firing. An example is an alert that is firing indicating an entire cluster is not reachable. Alertmanager can mute all other alerts to reduce noise that is not helping to identify the root cause of the problem.
### Silences
Silences mute alerts for a given time, and utilize matchers in the same way that the routing tree does. They are configured through the Alertmanager web ui.
### High Availability
Alertmanager can be configured create a cluster for high availability. Traffic between Prometheus and Alertmanager should not be load balanced, instead Prometheus should be pointed at a list of all Alertmanager instances.
## Configuration
The configuration file defines inhibition rules, notification routes and notification receivers. Utilize the [visual editor](https://www.prometheus.io/webtools/alerting/routing-tree-editor?_gl=1*ks2oop*_ga*MjY1MTMxNzYyLjE3NDE4MDQ3MjY.*_ga_80ZM8LGB96*MTc0NDM3NzgyNy4xNS4xLjE3NDQzNzgyOTEuMC4wLjA.) to build a routing tree. Alertmanager can reload its configuration at runtime by sending a POST to `/-/reload`.
### Routes
The routing configuration defines a path that received alerts will traverse to determine how they will be handled. The routing tree contains a top level route that matches every received alert, meaning it must not define any matchers. An alert enters at this top level route, and then traverses its child nodes. If `continue` is set to false, it stops after the first matching child and does not match subsequent siblings. If an alert does not match any child nodes the alert is handled by the current node.
### Time Interval
Alertmanager supports defining time intervals that can be used for fields such as `mute_time_intervals` and `active_time_intervals` in a route that control when a route is muted or active.
###### Example Time Interval Config
```yaml
name: time-example
time_intervals:
- times:
  - start_time: 05:00
    end_time: 12:30
  weekdays:
  - ['monday:wednesday', 'saturday', 'sunday']
  days_of_month:
  - ["1:5", "-3:-1"]
  month_range:
  - ["1:3", "may:august", "december"]
  year_range:
  - ["2020:2022", "2030"]
  location: "Australia/Sydney"
```
### Inhibition Rules
Inhibition allows muting alerts based on the presence of another set of alerts. Users can establish dependencies between systems and services and only receive the most relevant of a set of connected alerts during an outage.
### Receivers
Receivers are a named configuration of one or more notification integrations. This is where the actual connection with where the notification is being sent is defined. There are a number of different systems and settings that can be configured to properly send notifications, these settings can be found under the [receiver](https://prometheus.io/docs/alerting/latest/configuration/#receiver) specification.

----------------------------------------------
# Organizational Methods to Not Fall Behind
- Monthly new technology meeting
	- Present a new project, updates to existing technology, or other similar items to organization
- Provide leeway for organization to experiment and test with new technology and methods
- Allow for capacity to be spent to keep things up to date or transition to new technologies